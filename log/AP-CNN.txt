2020-12-30 15:27:46 INFO: Global Config:
	PAD_WORD = <UNK>
	a_length = 100
	answer_dict_file = data/insuranceQA/answers.label.token_idx
	batch_size = 20
	device = cuda:0
	kernel_count = 400
	kernel_size = 3
	l2_regularization = 1e-06
	learning_rate = 1.1
	loss_margin = 0.5
	lr_decay = Reciprocal
	lr_decay_gamma = 1.0
	model_name = AP-CNN
	punctuation_file = data/punctuations.txt
	q_length = 20
	qa_dev_file = data/insuranceQA/question.dev.label.token_idx.pool
	qa_test1_file = data/insuranceQA/question.test1.label.token_idx.pool
	qa_test2_file = data/insuranceQA/question.test2.label.token_idx.pool
	qa_train_file = data/insuranceQA/question.train.token_idx.label
	qa_vocab_file = data/insuranceQA/vocabulary
	rnn_hidden = 150
	test_batch_size = 128
	train_epochs = 20
	train_neg_count = 50
	trained_model = model/model_name_here
	word2vec_file = embedding/glove.6B.100d.txt

2020-12-30 15:28:05 INFO: Dataset train: 18532 samples.
2020-12-30 15:28:05 INFO: Dataset valid: 494985 samples.
2020-12-30 15:28:43 INFO: Initial valid accuracy 11.00%, MRR 0.185111
2020-12-30 15:32:17 INFO: Epoch   0; learning rate 1.1000; train loss 0.487541; valid accuracy 32.20%, MRR 0.4357
2020-12-30 15:35:33 INFO: Epoch   1; learning rate 0.5500; train loss 0.440792; valid accuracy 47.80%, MRR 0.6001
2020-12-30 15:38:36 INFO: Epoch   2; learning rate 0.3667; train loss 0.408396; valid accuracy 54.00%, MRR 0.6515
2020-12-30 15:41:39 INFO: Epoch   3; learning rate 0.2750; train loss 0.386254; valid accuracy 44.90%, MRR 0.5658
2020-12-30 15:44:43 INFO: Epoch   4; learning rate 0.2200; train loss 0.370134; valid accuracy 56.30%, MRR 0.6754
2020-12-30 15:47:45 INFO: Epoch   5; learning rate 0.1833; train loss 0.356297; valid accuracy 54.40%, MRR 0.6606
2020-12-30 15:50:48 INFO: Epoch   6; learning rate 0.1571; train loss 0.345052; valid accuracy 58.00%, MRR 0.6903
2020-12-30 15:53:49 INFO: Epoch   7; learning rate 0.1375; train loss 0.335073; valid accuracy 58.30%, MRR 0.6938
2020-12-30 15:56:49 INFO: Epoch   8; learning rate 0.1222; train loss 0.326591; valid accuracy 53.80%, MRR 0.6544
2020-12-30 15:59:49 INFO: Epoch   9; learning rate 0.1100; train loss 0.319537; valid accuracy 58.30%, MRR 0.6932
2020-12-30 16:02:50 INFO: Epoch  10; learning rate 0.1000; train loss 0.313105; valid accuracy 60.10%, MRR 0.7135
2020-12-30 16:05:50 INFO: Epoch  11; learning rate 0.0917; train loss 0.306954; valid accuracy 57.50%, MRR 0.6899
2020-12-30 16:08:45 INFO: Epoch  12; learning rate 0.0846; train loss 0.300621; valid accuracy 58.30%, MRR 0.6946
2020-12-30 16:11:44 INFO: Epoch  13; learning rate 0.0786; train loss 0.295130; valid accuracy 61.40%, MRR 0.7198
2020-12-30 16:14:43 INFO: Epoch  14; learning rate 0.0733; train loss 0.290081; valid accuracy 62.20%, MRR 0.7245
2020-12-30 16:17:41 INFO: Epoch  15; learning rate 0.0688; train loss 0.286520; valid accuracy 61.00%, MRR 0.7160
2020-12-30 16:20:39 INFO: Epoch  16; learning rate 0.0647; train loss 0.282368; valid accuracy 59.80%, MRR 0.7119
2020-12-30 16:23:38 INFO: Epoch  17; learning rate 0.0611; train loss 0.278611; valid accuracy 59.40%, MRR 0.7008
2020-12-30 16:26:36 INFO: Epoch  18; learning rate 0.0579; train loss 0.273319; valid accuracy 60.50%, MRR 0.7163
2020-12-30 16:29:34 INFO: Epoch  19; learning rate 0.0550; train loss 0.270060; valid accuracy 60.90%, MRR 0.7163
2020-12-30 16:29:34 INFO: End of training! Time used 3655 seconds.
2020-12-30 16:30:06 INFO: Test accuracy 62.20%; MRR 0.7245 Time used 32S.
2020-12-30 16:31:06 INFO: Test accuracy 65.06%; MRR 0.7438 Time used 57S.
2020-12-30 16:32:10 INFO: Test accuracy 58.83%; MRR 0.6963 Time used 60S.
